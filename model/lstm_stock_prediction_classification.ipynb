{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPaNJQmqZ0r4vh6XLnYB1UR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"5bvh8juq10x9"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from pandas_datareader import data\n","import yfinance as yf\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, LSTM, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from keras.preprocessing.sequence import TimeseriesGenerator\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error, accuracy_score, confusion_matrix, precision_score, classification_report\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV\n","from scipy.stats import randint as sp_randint\n","from scipy.stats import uniform as sp_uniform\n","import matplotlib.dates as mdates\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","path = '/content/gdrive/MyDrive/Colab_Notebooks/FYP/'"]},{"cell_type":"code","source":["# Read csv\n","full_training_data = pd.read_csv(path+'/data/full_training_data_cleaned.csv',index_col=False)"],"metadata":{"id":"o5dCSxwx15zW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Min-Max scaling\n","min_max_column = ['Open', 'High', 'Low', 'Volume',\n","                  'wsentiments', 'HSI_overnight_ret',\n","                  'HSI_intraday_overnight_ret_diff', 'CSI300_overnight_ret',\n","                  'SSE50_overnight_ret', 'HSI_stoch_k', 'HSI_rsi', 'HSI_daily_ret',\n","                  'HSI_intraday_ret', 'HSI_ret_range']\n","\n","mms_X = MinMaxScaler()\n","full_training_data[min_max_column] = mms_X.fit_transform(full_training_data[min_max_column])\n","\n","mms_y = MinMaxScaler()\n","full_training_data['Adj Close'] = mms_y.fit_transform(full_training_data[['Adj Close']])"],"metadata":{"id":"EL9zZtGo151i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Data Transformation for buy/sell/neutral label\n","full_training_data['HSI_OO_ter_0.005'] = full_training_data['HSI_OO_ter_0.005'].map({'buy':1, 'sell':-1, 'neutral':0})"],"metadata":{"id":"xDnwcDR21531"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Feature selection\n","\n","classification_feature_column = ['Open', 'High', 'Low', 'Volume', 'HSI_overnight_ret',\n","                             'HSI_intraday_overnight_ret_diff',\n","                             'CSI300_overnight_ret', 'SSE50_overnight_ret',\n","                             'HSI_stoch_k', 'HSI_rsi', 'HSI_daily_ret',\n","                             'HSI_disc_macd_1', 'HSI_intraday_ret',\n","                             'HSI_ret_range', 'HSI_OO_ter_0.005']\n","\n","classification_nlp_column = ['Open', 'High', 'Low', 'Volume', 'HSI_overnight_ret',\n","                         'HSI_intraday_overnight_ret_diff',\n","                         'CSI300_overnight_ret', 'SSE50_overnight_ret',\n","                         'HSI_stoch_k', 'HSI_rsi', 'HSI_daily_ret',\n","                         'HSI_disc_macd_1', 'HSI_intraday_ret', 'HSI_ret_range',\n","                         'wsentiments', 'HSI_OO_ter_0.005']\n","\n","classification_feature_df = full_training_data[classification_feature_column]\n","classification_nlp_df = full_training_data[classification_nlp_column]"],"metadata":{"id":"OyabO_Tw156-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create dataset for sequential input\n","def create_dataset(dataset, look_back):\n","    dataX, dataY = [], []\n","    num = dataset.shape[1] - 1\n","    for i in range(len(dataset) - look_back - 1):\n","        a = dataset[i:(i + look_back), : -1]\n","        dataX.append(a)\n","        dataY.append(dataset[i + look_back, num])\n","    return np.array(dataX), np.array(dataY)"],"metadata":{"id":"QACUtsLp159l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training\n","np.random.seed(7)\n","classification_feature_df_values = classification_feature_df.values\n","classification_nlp_df_values = classification_nlp_df.values\n","look_back = 10\n","\n","def train(regression_df_values, version):\n","  train_size = int(len(regression_df_values) * 0.7)\n","  val_size = int(len(regression_df_values) * 0.15)\n","  test_size = len(regression_df_values) - train_size - val_size\n","  train, val, test = regression_df_values[0:train_size+1, :], regression_df_values[train_size:train_size+val_size+1, :], regression_df_values[train_size+val_size:len(regression_df_values)+1, :]\n","  num = train.shape[1] - 1\n","\n","  trainX, trainY = create_dataset(train, look_back)\n","  valX, valY = create_dataset(val, look_back)\n","  testX, testY = create_dataset(test, look_back)\n","  trainX = np.reshape(trainX, (trainX.shape[0], look_back, num))\n","  valX = np.reshape(valX, (valX.shape[0], look_back, num))\n","  testX = np.reshape(testX, (testX.shape[0],look_back, num))\n","\n","  model=Sequential()\n","  model.add(LSTM(1024,input_shape=(look_back,num)))\n","  model.add(Dense(1))\n","  optimizer = Adam(lr=0.001)\n","  model.compile(loss='mean_squared_error', optimizer=optimizer)\n","  model.summary()\n","\n","  model.fit(trainX, trainY, validation_data=(valX, valY), epochs=20, batch_size=64, verbose=1)\n","  train_predict=model.predict(trainX)\n","  val_predict=model.predict(valX)\n","  test_predict=model.predict(testX)\n","\n","  train_predict = list(map(lambda x: -1 if (x < -0.5) else (0 if (x < 0.5) else 1), train_predict))\n","  val_predict = list(map(lambda x: -1 if (x < -0.5) else (0 if (x < 0.5) else 1), val_predict))\n","  test_predict = list(map(lambda x: -1 if (x < -0.5) else (0 if (x < 0.5) else 1), test_predict))\n","\n","  train_pred_df = pd.DataFrame({'Date': full_training_data.loc[look_back:train_size-1, 'Date'], 'Predicted': train_predict})\n","  val_pred_df = pd.DataFrame({'Date': full_training_data.loc[train_size+look_back+1:train_size+val_size, 'Date'], 'Predicted': val_predict})\n","  test_pred_df = pd.DataFrame({'Date': full_training_data.loc[train_size+val_size+look_back+1:train_size+val_size+test_size, 'Date'], 'Predicted': test_predict})\n","\n","  result = pd.concat([train_pred_df, val_pred_df])\n","  result = pd.concat([result, test_pred_df])\n","  result = result.sort_values(by='Date').reset_index(drop=True)\n","\n","  # output result\n","  result.to_csv(path+f'lstm_stock_prediction_classification_{version}.csv', index=False)\n","\n","  print(f\"Accuracy of training: {accuracy_score(trainY, train_predict)}\")\n","  print(f\"Accuracy of validation: {accuracy_score(valY, val_predict)}\")\n","  print(f\"Accuracy of testing: {accuracy_score(testY, test_predict)}\")\n","\n","  # Calculating the precision score of classifier\n","  print(f\"Precision Score of training: {precision_score(trainY, train_predict, average=None)}\")\n","  print(f\"Precision Score of training: {precision_score(valY, val_predict, average=None)}\")\n","  print(f\"Precision Score of testing: {precision_score(testY, test_predict, average=None)}\")\n","\n","  # confusion matrix function a matrix containing the summary of predictions\n","  print(f\"Confusion matrix of training: {confusion_matrix(trainY, train_predict)}\")\n","  print(f\"Confusion matrix of validation: {confusion_matrix(valY, val_predict)}\")\n","  print(f\"Confusion matrix of testing: {confusion_matrix(testY, test_predict)}\")\n","\n","  print(f\"Classification report of training: {classification_report(trainY, train_predict, digits=3)}\")\n","  print(f\"Classification report of validation: {classification_report(valY, val_predict, digits=3)}\")\n","  print(f\"Classification report of testing: {classification_report(testY, test_predict, digits=3)}\")\n","\n","  return train, val, test, trainY, valY, testY, train_predict, val_predict, test_predict, train_size, val_size, test_size"],"metadata":{"id":"uzpLyWNL16ED"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**LSTM Vanilla + Feature**"],"metadata":{"id":"3E8hrF2pjIiC"}},{"cell_type":"code","source":["trainX, valX, testX, trainY, valY, testY, train_predict, val_predict, test_predict, train_size, val_size, test_size = train(regression_feature_df_values, 'feature')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_GbNwgWTbPIf","executionInfo":{"status":"ok","timestamp":1690611237355,"user_tz":-480,"elapsed":138481,"user":{"displayName":"kw wu","userId":"09202500041014466301"}},"outputId":"84077674-c123-4883-9010-9b875d0e98d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm (LSTM)                 (None, 1024)              4255744   \n","                                                                 \n"," dense (Dense)               (None, 1)                 1025      \n","                                                                 \n","=================================================================\n","Total params: 4,256,769\n","Trainable params: 4,256,769\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/20\n","8/8 [==============================] - 9s 804ms/step - loss: 0.7437 - val_loss: 0.8900\n","Epoch 2/20\n","8/8 [==============================] - 7s 944ms/step - loss: 0.7096 - val_loss: 0.7872\n","Epoch 3/20\n","8/8 [==============================] - 6s 705ms/step - loss: 0.6629 - val_loss: 0.8074\n","Epoch 4/20\n","8/8 [==============================] - 7s 897ms/step - loss: 0.6597 - val_loss: 0.7712\n","Epoch 5/20\n","8/8 [==============================] - 6s 725ms/step - loss: 0.6402 - val_loss: 0.7656\n","Epoch 6/20\n","8/8 [==============================] - 7s 903ms/step - loss: 0.6244 - val_loss: 0.7383\n","Epoch 7/20\n","8/8 [==============================] - 6s 732ms/step - loss: 0.6023 - val_loss: 0.6914\n","Epoch 8/20\n","8/8 [==============================] - 7s 888ms/step - loss: 0.5518 - val_loss: 0.6379\n","Epoch 9/20\n","8/8 [==============================] - 6s 713ms/step - loss: 0.5689 - val_loss: 0.7001\n","Epoch 10/20\n","8/8 [==============================] - 6s 820ms/step - loss: 0.5578 - val_loss: 0.6509\n","Epoch 11/20\n","8/8 [==============================] - 7s 776ms/step - loss: 0.5237 - val_loss: 0.5911\n","Epoch 12/20\n","8/8 [==============================] - 6s 789ms/step - loss: 0.4893 - val_loss: 0.5957\n","Epoch 13/20\n","8/8 [==============================] - 7s 900ms/step - loss: 0.4868 - val_loss: 0.5540\n","Epoch 14/20\n","8/8 [==============================] - 6s 755ms/step - loss: 0.4696 - val_loss: 0.5697\n","Epoch 15/20\n","8/8 [==============================] - 7s 868ms/step - loss: 0.4558 - val_loss: 0.5372\n","Epoch 16/20\n","8/8 [==============================] - 6s 741ms/step - loss: 0.4396 - val_loss: 0.5354\n","Epoch 17/20\n","8/8 [==============================] - 7s 910ms/step - loss: 0.4369 - val_loss: 0.5447\n","Epoch 18/20\n","8/8 [==============================] - 6s 718ms/step - loss: 0.4212 - val_loss: 0.5157\n","Epoch 19/20\n","8/8 [==============================] - 7s 939ms/step - loss: 0.4181 - val_loss: 0.5402\n","Epoch 20/20\n","8/8 [==============================] - 6s 727ms/step - loss: 0.4093 - val_loss: 0.5531\n","16/16 [==============================] - 2s 86ms/step\n","4/4 [==============================] - 0s 119ms/step\n","4/4 [==============================] - 1s 180ms/step\n","Accuracy of training: 0.531496062992126\n","Accuracy of validation: 0.42574257425742573\n","Accuracy of testing: 0.44\n","Precision Score of training: [0.86792453 0.39339339 0.76229508]\n","Precision Score of training: [1.         0.22058824 0.80769231]\n","Precision Score of testing: [1.         0.30434783 0.63636364]\n","Confusion matrix of training: [[ 46 119   5]\n"," [  6 131  24]\n"," [  1  83  93]]\n","Confusion matrix of validation: [[ 7 36  1]\n"," [ 0 15  4]\n"," [ 0 17 21]]\n","Confusion matrix of testing: [[ 9 36  1]\n"," [ 0 21  7]\n"," [ 0 12 14]]\n","Classification report of training:               precision    recall  f1-score   support\n","\n","        -1.0      0.868     0.271     0.413       170\n","         0.0      0.393     0.814     0.530       161\n","         1.0      0.762     0.525     0.622       177\n","\n","    accuracy                          0.531       508\n","   macro avg      0.675     0.537     0.522       508\n","weighted avg      0.681     0.531     0.523       508\n","\n","Classification report of validation:               precision    recall  f1-score   support\n","\n","        -1.0      1.000     0.159     0.275        44\n","         0.0      0.221     0.789     0.345        19\n","         1.0      0.808     0.553     0.656        38\n","\n","    accuracy                          0.426       101\n","   macro avg      0.676     0.500     0.425       101\n","weighted avg      0.781     0.426     0.431       101\n","\n","Classification report of testing:               precision    recall  f1-score   support\n","\n","        -1.0      1.000     0.196     0.327        46\n","         0.0      0.304     0.750     0.433        28\n","         1.0      0.636     0.538     0.583        26\n","\n","    accuracy                          0.440       100\n","   macro avg      0.647     0.495     0.448       100\n","weighted avg      0.711     0.440     0.423       100\n","\n"]}]},{"cell_type":"markdown","source":["**LSTM Vanilla + Feature + NLP**"],"metadata":{"id":"Cc9j4K0EjMny"}},{"cell_type":"code","source":["trainX, valX, testX, trainY, valY, testY, train_predict, val_predict, test_predict, train_size, val_size, test_size = train(regression_nlp_df_values,'nlp')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x0bf05S8bPKn","executionInfo":{"status":"ok","timestamp":1690611388410,"user_tz":-480,"elapsed":151073,"user":{"displayName":"kw wu","userId":"09202500041014466301"}},"outputId":"88a2acac-04de-4542-add1-e68dcbb5067c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_1 (LSTM)               (None, 1024)              4259840   \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 1025      \n","                                                                 \n","=================================================================\n","Total params: 4,260,865\n","Trainable params: 4,260,865\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/20\n","8/8 [==============================] - 8s 772ms/step - loss: 0.9457 - val_loss: 0.8050\n","Epoch 2/20\n","8/8 [==============================] - 7s 900ms/step - loss: 0.6814 - val_loss: 0.7919\n","Epoch 3/20\n","8/8 [==============================] - 6s 701ms/step - loss: 0.6835 - val_loss: 0.7976\n","Epoch 4/20\n","8/8 [==============================] - 7s 908ms/step - loss: 0.6524 - val_loss: 0.7688\n","Epoch 5/20\n","8/8 [==============================] - 6s 708ms/step - loss: 0.6500 - val_loss: 0.7627\n","Epoch 6/20\n","8/8 [==============================] - 7s 938ms/step - loss: 0.6472 - val_loss: 0.7597\n","Epoch 7/20\n","8/8 [==============================] - 6s 711ms/step - loss: 0.6270 - val_loss: 0.7299\n","Epoch 8/20\n","8/8 [==============================] - 7s 844ms/step - loss: 0.6074 - val_loss: 0.7204\n","Epoch 9/20\n","8/8 [==============================] - 6s 732ms/step - loss: 0.5845 - val_loss: 0.6652\n","Epoch 10/20\n","8/8 [==============================] - 6s 715ms/step - loss: 0.5454 - val_loss: 0.6305\n","Epoch 11/20\n","8/8 [==============================] - 7s 841ms/step - loss: 0.5158 - val_loss: 0.6418\n","Epoch 12/20\n","8/8 [==============================] - 6s 704ms/step - loss: 0.4878 - val_loss: 0.5745\n","Epoch 13/20\n","8/8 [==============================] - 7s 927ms/step - loss: 0.4832 - val_loss: 0.6063\n","Epoch 14/20\n","8/8 [==============================] - 6s 708ms/step - loss: 0.4720 - val_loss: 0.5529\n","Epoch 15/20\n","8/8 [==============================] - 9s 1s/step - loss: 0.4521 - val_loss: 0.6619\n","Epoch 16/20\n","8/8 [==============================] - 6s 742ms/step - loss: 0.4778 - val_loss: 0.5721\n","Epoch 17/20\n","8/8 [==============================] - 7s 888ms/step - loss: 0.4548 - val_loss: 0.5258\n","Epoch 18/20\n","8/8 [==============================] - 6s 731ms/step - loss: 0.4273 - val_loss: 0.5304\n","Epoch 19/20\n","8/8 [==============================] - 6s 786ms/step - loss: 0.4207 - val_loss: 0.5654\n","Epoch 20/20\n","8/8 [==============================] - 6s 763ms/step - loss: 0.4089 - val_loss: 0.5879\n","16/16 [==============================] - 2s 86ms/step\n","4/4 [==============================] - 0s 75ms/step\n","4/4 [==============================] - 0s 70ms/step\n","Accuracy of training: 0.5118110236220472\n","Accuracy of validation: 0.38613861386138615\n","Accuracy of testing: 0.44\n","Precision Score of training: [0.95       0.38692098 0.79207921]\n","Precision Score of training: [1.         0.22368421 0.85      ]\n","Precision Score of testing: [1.         0.32467532 0.77777778]\n","Confusion matrix of training: [[ 38 128   4]\n"," [  2 142  17]\n"," [  0  97  80]]\n","Confusion matrix of validation: [[ 5 38  1]\n"," [ 0 17  2]\n"," [ 0 21 17]]\n","Confusion matrix of testing: [[ 5 40  1]\n"," [ 0 25  3]\n"," [ 0 12 14]]\n","Classification report of training:               precision    recall  f1-score   support\n","\n","        -1.0      0.950     0.224     0.362       170\n","         0.0      0.387     0.882     0.538       161\n","         1.0      0.792     0.452     0.576       177\n","\n","    accuracy                          0.512       508\n","   macro avg      0.710     0.519     0.492       508\n","weighted avg      0.717     0.512     0.492       508\n","\n","Classification report of validation:               precision    recall  f1-score   support\n","\n","        -1.0      1.000     0.114     0.204        44\n","         0.0      0.224     0.895     0.358        19\n","         1.0      0.850     0.447     0.586        38\n","\n","    accuracy                          0.386       101\n","   macro avg      0.691     0.485     0.383       101\n","weighted avg      0.798     0.386     0.377       101\n","\n","Classification report of testing:               precision    recall  f1-score   support\n","\n","        -1.0      1.000     0.109     0.196        46\n","         0.0      0.325     0.893     0.476        28\n","         1.0      0.778     0.538     0.636        26\n","\n","    accuracy                          0.440       100\n","   macro avg      0.701     0.513     0.436       100\n","weighted avg      0.753     0.440     0.389       100\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"rpVRSO70eeHN"},"execution_count":null,"outputs":[]}]}